{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb47b71",
   "metadata": {},
   "source": [
    "# Linear and logistic regression modeling, a case study with the NHANES data\n",
    "\n",
    "This notebook introduces two statistical modeling techniques: linear\n",
    "regression and logistic regression.  The focus here will be on fitting\n",
    "these two types of models to data, using Python statistical modeling\n",
    "libraries in the Jupyter notebook environment.  As with several previous\n",
    "case studies in this course, here we will be analyzing the\n",
    "[NHANES](https://www.cdc.gov/nchs/nhanes/index.htm) data, allowing us\n",
    "to illustrate the use of these two regression methods for addressing\n",
    "meaningful questions with actual data.\n",
    "\n",
    "Note that the NHANES data were collected as a designed survey, and in\n",
    "general should be analyzed as such.  This means that survey design\n",
    "information such as weights, strata, and clusters should be accounted\n",
    "for in any analysis using NHANES.  But to introduce how linear and\n",
    "logistic regression are used with independent data samples, or with convenience\n",
    "samples, we will not incorporate the survey structure of the NHANES sample\n",
    "into the analyses conducted here.\n",
    "\n",
    "As with our previous work, we will be using the\n",
    "[Pandas](http://pandas.pydata.org) library for data management, the\n",
    "[Numpy](http://www.numpy.org) library for numerical calculations, and\n",
    "the [Statsmodels](http://www.statsmodels.org) library for statistical\n",
    "modeling.\n",
    "\n",
    "We begin by importing the libraries that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d420ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/dz88q3d90njcf56flzg996140000gn/T/ipykernel_11285/3477311705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9467cd",
   "metadata": {},
   "source": [
    "Next we will load the data.  The NHANES study encompasses multiple\n",
    "waves of data collection.  Here we will only use the\n",
    "2015-2016 data.  As with most data sets, there are some missing values\n",
    "in the NHANES files.  While many of the methods demonstrated below would handle\n",
    "missing values automatically (at least in a crude way), here we drop\n",
    "up-front all rows with missing values in any of the key variables that\n",
    "we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731631c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 2015-2016 wave of NHANES data\n",
    "da = pd.read_csv(\"nhanes_2015_2016.csv\")\n",
    "\n",
    "# Drop unused columns, and drop rows with any missing values.\n",
    "vars = [\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDEDUC2\", \"BMXBMI\", \"SMQ020\"]\n",
    "da = da[vars].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ded9bc",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "We will focus initially on regression models in which systolic [blood\n",
    "pressure](https://en.wikipedia.org/wiki/Blood_pressure) (SBP)\n",
    "is the outcome (dependent) variable.  That is, we will\n",
    "predict SBP from other variables.  SBP is an important indicator of\n",
    "cardiovascular health.  It tends to increase with age, is greater for\n",
    "overweight people (i.e. people with greater body mass index or BMI),\n",
    "and also differs among demographic groups, for example among gender\n",
    "and ethnic groups.\n",
    "\n",
    "Since SBP is a quantitative variable, we will model it using linear\n",
    "regression.  Linear regression is the most widely-utilized form of\n",
    "statistical regression.  While linear regression is commonly used with\n",
    "quantitative outcome variables, it is not the only type of regression\n",
    "model that can be used with quantitative outcomes, nor is it the case\n",
    "that linear regression can only be used with quantitative outcomes.\n",
    "However, linear regression is a good default starting point for any\n",
    "regression analysis using a quantitative outcome variable.\n",
    "\n",
    "### Interpreting regression parameters in a basic model\n",
    "\n",
    "We start with a simple linear regression model with only one\n",
    "covariate, age, predicting SBP.  In the NHANES data, the variable\n",
    "[BPXSY1](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I.htm#BPXSY1)\n",
    "contains the first recorded measurement of SBP for a subject, and\n",
    "[RIDAGEYR](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#RIDAGEYR)\n",
    "is the subject's age in years.  The model that is fit in the next cell\n",
    "expresses the expected SBP as a linear function of age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS.from_formula(\"BPXSY1 ~ RIDAGEYR\", data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb35c7a",
   "metadata": {},
   "source": [
    "Much of the output above is not relevant for us, so focus on\n",
    "the center section of the output where the header begins with\n",
    "__coef__.  This section contains the estimated\n",
    "values of the parameters of the regression model, their standard\n",
    "errors, and other values that are used to quantify the uncertainty\n",
    "in the regression parameter estimates.  Note that the parameters\n",
    "of a regression model, which appear in the column labeled\n",
    "__coef__ in the table above,\n",
    "may also be referred to as *slopes* or *effects*.\n",
    "\n",
    "This fitted model implies that when\n",
    "comparing two people whose ages differ by one year, the older person\n",
    "will on average have 0.48 units higher SBP than the younger person.\n",
    "This difference is statistically significant, based on the p-value\n",
    "shown under the column labeled __`P>|t|`__.  This means that there\n",
    "is strong evidence that there is a real association between between systolic blood\n",
    "pressure and age in this population.\n",
    "\n",
    "SBP is measured in units of *millimeters of mercury*, expressed\n",
    "*mm/Hg*.  In order to better understand the meaning of the estimated\n",
    "regression parameter 0.48, we can look at the standard deviation of SBP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22816844",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.BPXSY1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69014e60",
   "metadata": {},
   "source": [
    "The standard deviation of around 18.5 is large compared to the\n",
    "regression slope of 0.48.  However the regression slope corresponds to\n",
    "the average change in SBP for a single year of age, and this effect\n",
    "accumulates with age.  Comparing a 40 year-old person to a 60 year-old\n",
    "person, there is a 20 year difference in age, which translates into a\n",
    "`20 * 0.48 = 9.6` unit difference in average SBP between these two\n",
    "people.  This difference is around half of one standard deviation, and\n",
    "would generally be considered to be an important and meaningful shift.\n",
    "\n",
    "### R-squared and correlation\n",
    "\n",
    "In the case of regression with a\n",
    "single independent variable, as we have here, there is a very close\n",
    "correspondence between the regression analysis and a Pearson\n",
    "correlation analysis, which we have discussed earlier in course 2.\n",
    "The primary summary statistic for assessing the strength of a\n",
    "predictive relationship in a regression model is the *R-squared*, which is\n",
    "shown to be 0.207 in the regression output above.  This means that 21%\n",
    "of the variation in SBP is explained by age.  Note that this value is\n",
    "exactly the same as the squared Pearson correlation coefficient\n",
    "between SBP and age, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59775b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = da[[\"BPXSY1\", \"RIDAGEYR\"]].corr()\n",
    "print(cc.BPXSY1.RIDAGEYR**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bfbfd0",
   "metadata": {},
   "source": [
    "There is a second way to interpret the R-squared, which makes use\n",
    "of the *fitted values* of the regression.  The fitted values are\n",
    "predictions of the blood pressure for each person in the data\n",
    "set, based on their covariate values.  In this case, the only\n",
    "covariate is age, so we are predicting each NHANES subject's\n",
    "blood pressure as a function of their age.  If we calculate\n",
    "the Pearson correlation coefficient between the fitted values\n",
    "from the regression, and the actual SBP values, and then square\n",
    "this correlation coefficient, we see\n",
    "that we also get the R-squared from the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.corrcoef(da.BPXSY1, result.fittedvalues)\n",
    "print(cc[0, 1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df49d317",
   "metadata": {},
   "source": [
    "Thus, we see that in a linear model fit with only one covariate,\n",
    "the regression R-squared is equal to the squared Pearson\n",
    "correlation between the covariate and the outcome, and is also\n",
    "equal to the squared Pearson correlation between the fitted\n",
    "values and the outcome.\n",
    "\n",
    "### Adding a second variable\n",
    "\n",
    "Above we considered a simple linear regression analysis with only one\n",
    "covariate (age) predicting systolic blood pressure (SBP).  The real\n",
    "power of regression analysis arises when we have more than one\n",
    "covariate predicting an outcome.  As noted above, SBP is expected to\n",
    "be related to gender as well as to age, so we next add gender to the\n",
    "model.  The NHANES variable for gender is named\n",
    "[RIAGENDR](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#RIAGENDR)\n",
    "\n",
    "We begin by creating a relabeled version of the gender variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76707107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a labeled version of the gender variable\n",
    "da[\"RIAGENDRx\"] = da.RIAGENDR.replace({1: \"Male\", 2: \"Female\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292cc013",
   "metadata": {},
   "source": [
    "Now we are ready to fit the linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx\", data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a9fd5c",
   "metadata": {},
   "source": [
    "The syntax `RIDAGEYR + RIAGENDRx` in the cell above does not mean\n",
    "that these two variables are literally added together.  Instead,\n",
    "it means that these variables are both included in the model as\n",
    "predictors of blood pressure (`BPXSY1`).\n",
    "\n",
    "The model that was fit above uses both age and gender to explain the\n",
    "variation in SBP.  It finds that two people with the same gender whose\n",
    "ages differ by one year tend to have blood pressure values differing\n",
    "by 0.47 units, which is essentially the same age parameter that we found above in\n",
    "the model based on age alone.  This model also shows us that comparing\n",
    "a man and a woman of the same age, the man will on average have 3.23 units\n",
    "greater SBP.\n",
    "\n",
    "It is very important to emphasize that the age coefficient of 0.47 is\n",
    "only meaningful when comparing two people of the same gender, and the\n",
    "gender coefficient of 3.23 is only meaningful when comparing two\n",
    "people of the same age.\n",
    "Moreover, these effects are additive, meaning that if we compare, say, a 50 year\n",
    "old man to a 40 year old woman, the man's blood pressure will on\n",
    "average be around 3.23 + 10*0.47 = 7.93 units higher, with the first\n",
    "term in this sum being attributable to gender, and the second term\n",
    "being attributable to age.\n",
    "\n",
    "We noted above that the regression coefficient for age did not change\n",
    "by much when we added gender to the model.  It is important to note\n",
    "however that in general, the estimated coefficient of a variable in a\n",
    "regression model will change when other variables are added or\n",
    "removed.  The only circumstance in which a regresion parameters is unchanged\n",
    "when other variables are added or removed from the model is when those\n",
    "variables are uncorrelated with the variables that remain in the model.\n",
    "\n",
    "Below we confirm that gender and age are nearly uncorrelated in this\n",
    "data set (the correlation of around -0.02 is negligible).  Thus, it is\n",
    "expected that when we add gender to the model, the age coefficient\n",
    "is unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to use the original, numerical version of the gender\n",
    "# variable to calculate the correlation coefficient.\n",
    "da[[\"RIDAGEYR\", \"RIAGENDR\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47431b08",
   "metadata": {},
   "source": [
    "Observe that in the regression output shown above, an R-squared value of 0.215 is\n",
    "listed.  Earlier we saw that for a model with only one covariate,\n",
    "the R-squared from the regression could be defined in two different\n",
    "ways, either as the squared correlation coefficient between the covariate and the outcome,\n",
    "or as the squared correlation coefficient between the fitted values and the outcome.\n",
    "When more than one covariate is in the model, only the second of these\n",
    "two definitions continues to hold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.corrcoef(da.BPXSY1, result.fittedvalues)\n",
    "print(cc[0, 1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30689b",
   "metadata": {},
   "source": [
    "### Categorical variables and reference levels\n",
    "\n",
    "In the model fit above, gender is a categorical variable, and only a\n",
    "coefficient for males is included in the regression output (i.e. there\n",
    "is no coefficient for females in the tables above).  Whenever a categorical variable is\n",
    "used as a covariate in a regression model, one level of the variable\n",
    "is omitted and is automatically given a coefficient of zero.  This\n",
    "level is called the *reference level* of the covariate.  Here, the\n",
    "female level of the gender variable is the reference level.  This does\n",
    "not mean that being a woman has no impact on blood pressure.  It\n",
    "simply means that we have written the model so that female blood\n",
    "pressure is the default, and the coefficient for males (3.23) shifts\n",
    "the blood pressure by that amount for males only.\n",
    "\n",
    "We could alternatively have set 'male' to be the reference level, in\n",
    "which case males would be the default, and the female coefficient\n",
    "would have been around -3.23 (meaning that female blood pressure is\n",
    "3.23 units lower than the male blood pressure).\n",
    "\n",
    "When using a categorical variable as a predictor in a regression\n",
    "model, it is recoded into \"dummy variables\" (also known as \"indicator\n",
    "variables\").  A dummy variable for a single level, say `a`, of a\n",
    "variable `x`, is a variable that is equal to `1` when `x=a` and is\n",
    "equal to `0` when `x` is not equal to `a`.  These dummy variables are\n",
    "all included in the regression model, to represent the variable that they\n",
    "are derived from.\n",
    "\n",
    "Statsmodels, like most software, will automatically recode a\n",
    "categorical variable into dummy variables, and will select a reference\n",
    "level (it is possible to override this choice, but we do not cover that\n",
    "here).  When interpreting the regression output, the level that is\n",
    "omitted should be seen as having a coefficient of 0, with a standard\n",
    "error of 0.  It is important to note that the selection of a reference\n",
    "level is arbitrary and does not imply an assumption or constraint\n",
    "about the model, or about the population that it is intended to capture.\n",
    "\n",
    "### A model with three variables\n",
    "\n",
    "Next we add a third variable, body mass index (BMI), to the model predicting SBP.\n",
    "[BMI](https://en.wikipedia.org/wiki/Body_mass_index) is a measure that is used\n",
    "to assess if a person has healthy weight given their height.\n",
    "[BMXBMI](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BMX_I.htm#BMXBMI)\n",
    "is the NHANES variable containing the BMI value for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS.from_formula(\"BPXSY1 ~ RIDAGEYR + BMXBMI + RIAGENDRx\", data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53df18",
   "metadata": {},
   "source": [
    "Not surprisingly, BMI is positively associated with SBP.  Given two\n",
    "subjects with the same gender and age, and whose BMI differs by 1\n",
    "unit, the person with greater BMI will have, on average, 0.31 units\n",
    "greater systolic blood pressure (SBP).  Also note that after adding\n",
    "BMI to the model, the coefficient for gender became somewhat greater.\n",
    "This is due to the fact that the three covariates in the model, age,\n",
    "gender, and BMI, are mutually correlated, as shown next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d65614",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[[\"RIDAGEYR\", \"RIAGENDR\", \"BMXBMI\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7027b66",
   "metadata": {},
   "source": [
    "Although the correlations among these three variables are not strong,\n",
    "they are sufficient to induce fairly substantial differences in the\n",
    "regression coefficients (e.g. the gender coefficient changes from 3.23\n",
    "to 3.58).  In this example, the gender effect becomes larger after we\n",
    "control for BMI - we can take this to mean that BMI was masking part\n",
    "of the association between gender and blood pressure.  In other settings, including\n",
    "additional covariates can reduce the association between a covariate\n",
    "and an outcome.\n",
    "\n",
    "### Visualization of the fitted models\n",
    "\n",
    "In this section we demonstrate some graphing techniques that can be\n",
    "used to gain a better understanding of a regression model that has\n",
    "been fit to data.\n",
    "\n",
    "We start with plots that allow us to visualize the fitted regression\n",
    "function, that is, the mean systolic blood pressure expressed as a\n",
    "function of the covariates.  These plots help to show the estimated\n",
    "role of one variable when the other variables are held fixed.  We will\n",
    "also plot 95% *simultaneous confidence bands* around these fitted\n",
    "lines.  Although the estimated mean curve is never exact based on a\n",
    "finite sample of data, we can be 95% confident that the true mean\n",
    "curve falls somewhere within the shaded regions of the plots below.\n",
    "\n",
    "This type of plot requires us to fix the values of all variables\n",
    "other than the independent variable (SBP here), and one independent\n",
    "variable that we call the *focus variable* (which is age here).\n",
    "Below we fix the gender as \"female\" and the BMI as 25.  Thus,\n",
    "the graphs below show the relationship between expected SBP\n",
    "and age for women with BMI equal to 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.predict_functional import predict_functional\n",
    "\n",
    "# Fix certain variables at reference values.  Not all of these\n",
    "# variables are used here, but we provide them with a value anyway\n",
    "# to prevent a warning message from appearing.\n",
    "values = {\"RIAGENDRx\": \"Female\", \"RIAGENDR\": 1, \"BMXBMI\": 25,\n",
    "          \"DMDEDUC2\": 1, \"RIDRETH1\": 1, \"SMQ020\": 1}\n",
    "\n",
    "# The returned values are the predicted values (pr), the confidence bands (cb),\n",
    "# and the function values (fv).\n",
    "pr, cb, fv = predict_functional(result, \"RIDAGEYR\",\n",
    "                values=values, ci_method=\"simultaneous\")\n",
    "\n",
    "ax = sns.lineplot(fv, pr, lw=4)\n",
    "ax.fill_between(fv, cb[:, 0], cb[:, 1], color='grey', alpha=0.4)\n",
    "ax.set_xlabel(\"Age\")\n",
    "_ = ax.set_ylabel(\"SBP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41447c",
   "metadata": {},
   "source": [
    "The analogous plot for BMI is shown next.  Here we fix the\n",
    "gender as \"female\" and the age at 50, so we are looking\n",
    "at the relationship between expected SBP and age for women\n",
    "of age 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "del values[\"BMXBMI\"] # Delete this as it is now the focus variable\n",
    "values[\"RIDAGEYR\"] = 50\n",
    "pr, cb, fv = predict_functional(result, \"BMXBMI\",\n",
    "                values=values, ci_method=\"simultaneous\")\n",
    "\n",
    "ax = sns.lineplot(fv, pr, lw=4)\n",
    "ax.fill_between(fv, cb[:, 0], cb[:, 1], color='grey', alpha=0.4)\n",
    "ax.set_xlabel(\"BMI\")\n",
    "_ = ax.set_ylabel(\"SBP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488542c",
   "metadata": {},
   "source": [
    "The error band for BMI is notably wider than the error band for age,\n",
    "indicating that there is less certainty about the relationship between\n",
    "BMI and SBP compared to the relationship between age and SBP.\n",
    "\n",
    "The discussion so far has primarily focused on the mean structure of\n",
    "the population, that is, the model for the average SBP of a person\n",
    "with a given age, gender, and BMI.  A regression model can also be\n",
    "used to assess the *variance structure* of the population, that is,\n",
    "how much and in what manner the observations deviate from their mean.\n",
    "We will focus on informal, graphical methods for assessing this.\n",
    "\n",
    "To begin with, we plot the residuals against the fitted values.\n",
    "Recall that the fitted values are the estimated means for each\n",
    "observation, and the residuals are the difference between an\n",
    "observation and its fitted mean.  For example, the model may estimate\n",
    "that a 50 year old female will have on average an SBP of 125.  But a\n",
    "specific 50 year old female may have a blood pressure of 110 or 150,\n",
    "for example.  The fitted values for both of these women are 125, and\n",
    "their residuals are -15, and 25, respectively.\n",
    "\n",
    "The simplest variance pattern that we can see in a linear regression\n",
    "occurs when the points are scattered around the mean, with the same\n",
    "degree of scatter throughout the range of the covariates.  When there\n",
    "are multiple covariates, it is hard to assess whether the variance is\n",
    "uniform throughout this range, but we can easily check for a\n",
    "\"mean/variance relationship\", in which there is a systematic relationship\n",
    "between the variance and the mean, i.e. the variance either increases\n",
    "or decreases systematically with the mean.  The plot of residuals on fitted values is\n",
    "used to assess whether such a mean/variance relationship is present.\n",
    "\n",
    "Below we show the plot of residuals on fitted values for the NHANES\n",
    "data.  It appears that we have a modestly increasing mean/variance\n",
    "relationship.  That is, the scatter around the mean blood pressure is\n",
    "greater when the mean blood pressure itself is greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = sns.scatterplot(result.fittedvalues, result.resid)\n",
    "pp.set_xlabel(\"Fitted values\")\n",
    "_ = pp.set_ylabel(\"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58706559",
   "metadata": {},
   "source": [
    "A \"component plus residual plot\" or \"partial residual plot\" is\n",
    "intended to show how the data would look if all but one covariate\n",
    "could be fixed at reference values.  By controlling the values of\n",
    "these covariates, all remaining variation is due either to the \"focus\n",
    "variable\" (the one variable that is left unfixed, and is plotted on\n",
    "the horizontal axis), or to sources of variation that are unexplained\n",
    "by any of the covariates.\n",
    "\n",
    "For example, the partial residual plot below shows how age (horizontal\n",
    "axis) and SBP (vertical axis) would be related if gender and BMI were\n",
    "fixed.  Note that the origin of the vertical axis in these plots is\n",
    "not meaningful (we are not implying that anyone's blood pressure would\n",
    "be negative), but the differences along the vertical axis are\n",
    "meaningful.  This plot implies that when BMI and gender are held\n",
    "fixed, the average blood pressures of an 80 and 18 year old differ by\n",
    "around 30 mm/Hg.  This plot also shows, as discussed above,\n",
    "that the deviations from the\n",
    "mean are somewhat smaller at the low end of the range compared to the\n",
    "high end of the range.  We also see that at the high end of the range, the\n",
    "deviations from the mean are somewhat right-skewed, with\n",
    "exceptionally high SBP values being more common than exceptionally low SBP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not part of the main Statsmodels API, so needs to be imported separately\n",
    "from statsmodels.graphics.regressionplots import plot_ccpr\n",
    "\n",
    "ax = plt.axes()\n",
    "plot_ccpr(result, \"RIDAGEYR\", ax)\n",
    "ax.lines[0].set_alpha(0.2) # Reduce overplotting with transparency\n",
    "_ = ax.lines[1].set_color('orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a3d8df",
   "metadata": {},
   "source": [
    "Next we have a partial residual plot that shows how BMI (horizontal\n",
    "axis) and SBP (vertical axis) would be related if gender and age were\n",
    "fixed.  Compared to the plot above, we see here that age is more\n",
    "uniformly distributed than BMI.  Also, it appears that there is more\n",
    "scatter in the partial residuals for BMI compared to what we saw above\n",
    "for age. Thus there seems to be less information about SBP in BMI,\n",
    "although a trend certainly exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "plot_ccpr(result, \"BMXBMI\", ax)\n",
    "ax.lines[0].set_alpha(0.2)\n",
    "ax.lines[1].set_color(\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b75551",
   "metadata": {},
   "source": [
    "Another important plot used for understanding a regression model is an \"added variable plot\".  This is a plot\n",
    "that may reveal nonlinearity in the relationship between one covariate and the outcome.  Below, we create\n",
    "an added variable plot for age as a predictor of SBP.  Note that the two variables being plotted (age and blood pressure) have been centered.  The scale of the variables is unchanged, but the origin has been translated to zero.  The red line is an estimte of the relationship between age and blood pressure.  Unlike the relationship in the model, it is not forced to be linear, and there is in fact a hint that the shape is slightly flatter for the first 15 years or so of age.  This would imply that blood pressure increases slightly more slowly for people in theie 20s and early 30s, then begins increasing faster after that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68315a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not part of the main Statsmodels API, so needs to be imported separately\n",
    "from statsmodels.graphics.regressionplots import add_lowess\n",
    "\n",
    "# This is an equivalent way to fit a linear regression model, it needs to be\n",
    "# done this way to be able to make the added variable plot\n",
    "model = sm.GLM.from_formula(\"BPXSY1 ~ RIDAGEYR + BMXBMI + RIAGENDRx\", data=da)\n",
    "result = model.fit()\n",
    "result.summary()\n",
    "\n",
    "fig = result.plot_added_variable(\"RIDAGEYR\")\n",
    "ax = fig.get_axes()[0]\n",
    "ax.lines[0].set_alpha(0.2)\n",
    "_ = add_lowess(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02e3cd",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "We now turn to regression models for *binary* outcome variables,\n",
    "meaning an outcome that can take on only two distinct values.  For\n",
    "illustration, we will work with the NHANES variable\n",
    "[SMQ020](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/SMQ_I.htm#SMQ020),\n",
    "which asks whether a person has smoked at least 100 cigarettes in\n",
    "their lifetime (if this is the case, we say that the person has a\n",
    "\"smoking history\").  Below we create a version of this variable in\n",
    "which smoking and non-smoking are coded as 1 and 0, respectively, and\n",
    "rare responses like *don't know* and *refused to answer* are coded as\n",
    "missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26bb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"smq\"] = da.SMQ020.replace({2: 0, 7: np.nan, 9: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446215fa",
   "metadata": {},
   "source": [
    "### Odds and log odds\n",
    "\n",
    "Logistic regression provides a model for the *odds* of an event\n",
    "happening.  Recall that if an event has probability `p`, then the odds\n",
    "for this event is `p/(1-p)`.  The odds is a mathematical\n",
    "transformation of the probability onto a different scale.  For\n",
    "example, if the probability is 1/2, then the odds is 1.\n",
    "\n",
    "To begin, we look at the odds of alcohol use for women and men separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.crosstab(da.RIAGENDRx, da.smq).apply(lambda x: x/x.sum(), axis=1)\n",
    "c[\"odds\"] = c.loc[:, 1] / c.loc[:, 0]\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6bbdc",
   "metadata": {},
   "source": [
    "We see that the probability that a woman has ever smoked is\n",
    "substantially lower than the probability that a man has ever smoked\n",
    "(30% versus 51%).  This is reflected in the odds for a woman smoking\n",
    "being much less than 1 (around 0.47), while the odds for a man smoking\n",
    "is around 1.14.\n",
    "\n",
    "It is common to work with *odds ratios* when comparing two groups.\n",
    "This is simply the odds for one group divided by the odds for the\n",
    "other group.  The odds ratio for smoking, comparing males to females,\n",
    "is around 2.4.  In other words, a man has around 2.4 times greater\n",
    "odds of smoking than a woman (in the population represented by these\n",
    "data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec9b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.odds.Male / c.odds.Female"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18eb793",
   "metadata": {},
   "source": [
    "It is conventional to work with odds on the logarithmic scale.  To\n",
    "understand the motivation for doing this, first note that the neutral\n",
    "point for a probability is 0.5, which is equivalent to an odds of 1\n",
    "and a log odds of 0.  Populations where men smoke more than women will\n",
    "have odds between 1 and infinity, with the exact value depending on\n",
    "the magnitude of the relationship between the male and female smoking\n",
    "rates.  Populations where women smoke more than men would have odds\n",
    "falling between 0 and 1.\n",
    "\n",
    "We see that the scale of the odds statistic is not symmetric.  It is\n",
    "usually arbitrary in which order we compare two groups -- we could\n",
    "compare men to women, or compare women to men.  An odds of 2 (men have\n",
    "twice the odds of smoking as women) is equivalent in strength to an\n",
    "odds of 1/2 (women have twice the odds of smoking as men).  Taking the\n",
    "log of the odds centers the scale at zero, and symmetrizes the\n",
    "interpretation of the scale.\n",
    "\n",
    "To interpret the log odds when comparing two groups,\n",
    "it is important to remember the following facts:\n",
    "\n",
    "* A probability of 1/2, an odds of 1, and a log odds\n",
    "of 0 are all equivalent.\n",
    "\n",
    "* A positive log odds indicates that the first\n",
    "group being compared has greater odds (and greater probability) than\n",
    "the second group.\n",
    "\n",
    "* A negative log odds indicates that the second\n",
    "group being compared has greater odds (and greater probability) than\n",
    "the first group.\n",
    "\n",
    "* The scale of the log odds statistic is symmetric in\n",
    "the sense that a log odds of, say, 2, is equivalent in strength to a\n",
    "log odds of -2 (but with the groups swapped in terms of which has the\n",
    "greater probability).\n",
    "\n",
    "If you know that the log odds when comparing two groups is a given\n",
    "value, say 2, and you want to report the odds, you simply exponentiate\n",
    "the log odds to get the odds, e.g. `exp(2)` is around 7.4. Note\n",
    "however that you cannot recover the individual probabilities (or their\n",
    "ratio) from an odds ratio.`\n",
    "\n",
    "Below we show the log odds for smoking history status of females and\n",
    "males in the NHANES data.  The fact that the log odds for females is\n",
    "negative reflects that fact that substantially less than 50% of\n",
    "females have a history of smoking.  The log odds for males is closer to\n",
    "0, consistent with around half of males having a history of smoking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49520e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"logodds\"] = np.log(c.odds)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3eaab",
   "metadata": {},
   "source": [
    "### A basic logistic regression model\n",
    "\n",
    "Now that we have a clear understanding of log odds statistics, we will\n",
    "fit a logistic regression.  The dependent variable (outcome) of this\n",
    "initial model is smoking status, and the only covariate is gender.\n",
    "Thus, we are looking at gender as a predictor of smoking status.  We\n",
    "fit the model using the `GLM` function, where `GLM` stands for\n",
    "*Generalized Linear Model*.  Logistic regression is one type of GLM,\n",
    "a class which also includes many other regression methods such as Poisson\n",
    "regression that we do not discuss further here.  As with linear\n",
    "regression, logistic models also include an intercept parameter, but\n",
    "we are not focusing on that parameter now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a892300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.GLM.from_formula(\"smq ~ RIAGENDRx\", family=sm.families.Binomial(), data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e3e656",
   "metadata": {},
   "source": [
    "To see the connection between logistic regression and the log odds\n",
    "statistic, note that the logistic regression coefficient for male\n",
    "gender is exactly equal to the difference between the log odds\n",
    "statistics for males and females:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb555c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.logodds.Male - c.logodds.Female"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f6bcf",
   "metadata": {},
   "source": [
    "This relationship will always hold when conducting a logistic\n",
    "regression with a single binary covariate.\n",
    "\n",
    "In general, a logistic regression model will have multiple covariates\n",
    "that may not be binary, but there is still an important connection\n",
    "between logistic regression and odds ratios.  In this more general\n",
    "setting, we will use a more general type of odds ratio, which we will\n",
    "explore further next.\n",
    "\n",
    "### Adding additional covariates\n",
    "\n",
    "As with linear regression, we can include multiple covariates in a\n",
    "logistic regression.  Below we fit a logistic regression for smoking\n",
    "status using age (RIDAGEYR) and gender as covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12155c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.GLM.from_formula(\"smq ~ RIDAGEYR + RIAGENDRx\", family=sm.families.Binomial(), data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2af16f",
   "metadata": {},
   "source": [
    "Adding age to the model leads to a very small shift in the gender\n",
    "parameter (it changed from 0.885 to 0.892).  In general, regression\n",
    "coefficients can change a lot when adding or removing other variables\n",
    "from a model.  But in this case the change is quite minimal.  This\n",
    "fitted model suggests that older people are more likely to have a\n",
    "history of smoking than younger people.  The log odds for smoking\n",
    "increases by 0.017 for each year of age.  This effect is additive, so\n",
    "that comparing two people whose ages differ by 20 years, the log odds\n",
    "of the older person smoking will be around 0.34 units greater than the\n",
    "log odds for the younger person smoking, adn the odds for the older\n",
    "person smoking will be around `exp(0.34) = 1.4` times greater than\n",
    "the odds for the younger person smoking.\n",
    "\n",
    "The greater prevalence of smoking history among older people could be\n",
    "partly due to the definition of smoking status that we are using here -- an older person has\n",
    "had more time to smoke 99 cigarettes than a younger person.  However\n",
    "most people who smoke begin when they are young, and the smoking rate\n",
    "in the US has been slowly declining for several decades.  Thus, it is\n",
    "likely that the increased smoking levels in older people are driven\n",
    "primarily by real shifts in behavior.\n",
    "\n",
    "As with linear regression, the roles of age and gender in the logistic\n",
    "regression model can be seen as being additive, but here the additivity\n",
    "is on the scale of log odds, not odds or probabilities.  If we compare\n",
    "a 30 year old female to a 50 year old male, the log odds for the male\n",
    "being a smoker are `0.89 + 0.34 = 1.23` units greater than the log odds\n",
    "for the female being a smoker.  The value of 0.89 in this expression is\n",
    "the change attributable to gender, and the value of 0.34 is the change\n",
    "attributable to age.  Again, we can exponentiate to convert these\n",
    "effects from the log odds scale to the odds scale.  Since\n",
    "`exp(0.89 + 0.34) = exp(0.89)*exp(0.34) = 2.44*1.41` we can state\n",
    "that male gender is associated with a 2.44 fold increase in the odds\n",
    "of smoking, and 20 years of age is associated with a 1.41 fold increase\n",
    "in the odds for smoking.  These two effects are multiplied when\n",
    "discussing the odds, so a 50 year old man has `exp(1.23) = 3.42` fold\n",
    "greater odds of smoking than a 30 year old woman.\n",
    "\n",
    "In this logistic regression model with two covariates, the\n",
    "coefficients for age and gender both have interpretations in terms of\n",
    "*conditional log odds*.  This generalizes the interpretation of a\n",
    "logistic regression coefficient in terms of marginal log odds that we\n",
    "discussed above.  When there are two or more covariates in a logistic\n",
    "regression model, we always need to think in terms of conditional, not\n",
    "marginal log odds.\n",
    "\n",
    "Specifically, the coefficient of around 0.89 for male gender impacts the conditional\n",
    "log odds in the sense that when comparing a male to a female at a\n",
    "fixed age, the male will have 0.89 units greater log odds for smoking than\n",
    "the female.  This relationship holds within any age (i.e. it holds\n",
    "among all people of age 30, and among all people of age 70).  In this\n",
    "sense, it is a *conditional* coefficient because it is only\n",
    "interpretable when holding the other variables in the model fixed.\n",
    "Similarly, the coefficient of around 0.02 for age holds within a\n",
    "gender.  Comparing two females whose ages differ by one year, the\n",
    "older female has 0.02 units greater log odds for smoking than the\n",
    "younger female.  This same contrast holds for males.\n",
    "\n",
    "### A logistic regression model with three predictors\n",
    "\n",
    "Next we fit a logistic regression model, again for smoking, including\n",
    "educational attainment as a predictor.  The educational attainment in\n",
    "NHANES is called\n",
    "[DMDEDUC2](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#DMDEDUC2),\n",
    "and we will recode it so that the meaning of the levels becomes more\n",
    "clear.  We will call the recoded variable `DMDEDUC2x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a labeled version of the educational attainment variable\n",
    "da[\"DMDEDUC2x\"] = da.DMDEDUC2.replace({1: \"lt9\", 2: \"x9_11\", 3: \"HS\", 4: \"SomeCollege\",\n",
    "                                       5: \"College\", 7: np.nan, 9: np.nan})\n",
    "\n",
    "model = sm.GLM.from_formula(\"smq ~ RIDAGEYR + RIAGENDRx + DMDEDUC2x\", family=sm.families.Binomial(), data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e79a3e9",
   "metadata": {},
   "source": [
    "We see that the \"Female\" level of the gender variable, and the\n",
    "\"College\" level of the educational attainment variable are the\n",
    "reference levels, as they are not shown in the output above.  We have\n",
    "discussed the gender and age variables above, but the educational\n",
    "attainment variable is new for us.  All non-reference coefficients for\n",
    "the educational attainment are positive, while the `College`\n",
    "coefficient, as the reference coefficient, is exactly zero.  Thus, we\n",
    "see that people with a college degree have the lowest rate of smoking,\n",
    "followed by people with less than 9 years of schooling, then\n",
    "(after a large gap) people\n",
    "with some college, then people with a high school degree (and no\n",
    "college), and finally (with the greatest rate of smoking), people with\n",
    "9-11 years of schooling.  The overall story here is that smoking rates\n",
    "are much lower for people who graduated from college or did not start\n",
    "high school, presumably for very different reasons.  On the other\n",
    "hand, people with some high school, people who completed high school,\n",
    "and people who began but did not complete college have much higher\n",
    "rates of smoking.  The odds ratio between the former and the latter\n",
    "group depends on the specific subgroups being compared, but can be\n",
    "almost `3 = exp(1.09)`.\n",
    "\n",
    "As noted above when we were discussing linear regression, it is\n",
    "important to remember that a coefficient in a logistic regression are\n",
    "\"conditional\" on the other variables being held fixed.  For example,\n",
    "the log odds ratio of 1.09 between people with 9-11 years of schooling\n",
    "and people who completed college applies only when comparing people with\n",
    "the same age and gender.\n",
    "\n",
    "### Visualization of the fitted models\n",
    "\n",
    "Visualization of fitted logistic regression models is more challenging\n",
    "than visualization of fitted linear models, but is still worth\n",
    "pursuing.  We can begin by plotting the fitted proportion of the\n",
    "population that smokes, for various subpopulations defined by the\n",
    "regression model.  We will focus here on how the smoking rate varies\n",
    "with age, so we restrict the population to female college graduates.\n",
    "\n",
    "The following plot shows the fitted log odds (or logit) probability\n",
    "for the smoking outcome as a function of age.  The grey band is a\n",
    "simultaneous 95% simultaneous confidence band, as discussed above in\n",
    "the case of a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3407202",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {\"RIAGENDRx\": \"Female\", \"RIAGENDR\": 1, \"BMXBMI\": 25,\n",
    "          \"DMDEDUC2\": 1, \"RIDRETH1\": 1, \"SMQ020\": 1,\n",
    "          \"DMDEDUC2x\": \"College\", \"BPXSY1\": 120}\n",
    "\n",
    "pr, cb, fv = predict_functional(result, \"RIDAGEYR\",\n",
    "                values=values, ci_method=\"simultaneous\")\n",
    "\n",
    "ax = sns.lineplot(fv, pr, lw=4)\n",
    "ax.fill_between(fv, cb[:, 0], cb[:, 1], color='grey', alpha=0.4)\n",
    "ax.set_xlabel(\"Age\")\n",
    "ax.set_ylabel(\"Smoking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010d466",
   "metadata": {},
   "source": [
    "We can display the same plot in terms of probabilities instead of in\n",
    "terms of log odds.  The probability can be obtained from the log odds\n",
    "using the relationship `p = 1 / (1 + exp(-o))` where `o` is the log\n",
    "odds.  Note that while the age and log odds are linearly related, age\n",
    "has a curved relationship with probability.  This is necessary since\n",
    "probabilities must remain between 0 and 1, a linear relationship would\n",
    "eventually exit this interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = 1 / (1 + np.exp(-pr))\n",
    "cb1 = 1 / (1 + np.exp(-cb))\n",
    "ax = sns.lineplot(fv, pr1, lw=4)\n",
    "ax.fill_between(fv, cb1[:, 0], cb1[:, 1], color='grey', alpha=0.4)\n",
    "ax.set_xlabel(\"Age\", size=15)\n",
    "ax.set_ylabel(\"Smoking\", size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb5d2c",
   "metadata": {},
   "source": [
    "Next we turn to diagnostic plots that are intended to reveal certain\n",
    "aspects of the data that may not be correctly captured by the model.\n",
    "The three plots below are intended to reveal any curvature in the mean\n",
    "relationship between the outcome and one of the covariates. We used\n",
    "the partial regression plotting technique above for this same purpose\n",
    "when working with linear models.\n",
    "\n",
    "In the case of logistic regression, the three techniques\n",
    "demonstrated below can identify\n",
    "major discrepancies between the fitted model and the population, but\n",
    "evidence for small discrepancies is not reliable unless the sample\n",
    "size is very large.  The CERES technique has the strongest theoretical\n",
    "support.  Taken at face value, the plots below suggest that smoking\n",
    "rates may rise slightly faster for people between the ages of 20 and 35,\n",
    "and again for people between the ages of 50 and 60, with a period of minimal\n",
    "increase between these age intervals.  This would contradict the\n",
    "perfectly linear model for age (on the log odds scale)\n",
    "that we have specified in our model.\n",
    "These plotting techniques can be useful at identifying\n",
    "possible opportunities for future analysis with additional data, but\n",
    "do not identify features that can be claimed with high confidence\n",
    "using the present data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = result.plot_partial_residuals(\"RIDAGEYR\")\n",
    "ax = fig.get_axes()[0]\n",
    "ax.lines[0].set_alpha(0.2)\n",
    "\n",
    "_ = add_lowess(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = result.plot_added_variable(\"RIDAGEYR\")\n",
    "ax = fig.get_axes()[0]\n",
    "ax.lines[0].set_alpha(0.2)\n",
    "_ = add_lowess(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecc9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = result.plot_ceres_residuals(\"RIDAGEYR\")\n",
    "ax = fig.get_axes()[0]\n",
    "ax.lines[0].set_alpha(0.2)\n",
    "_ = add_lowess(ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
